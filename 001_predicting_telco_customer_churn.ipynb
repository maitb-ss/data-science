{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "001_predicting_telco_customer_churn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/machine-learning-ss/data-science/blob/master/001_predicting_telco_customer_churn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "suUd6CVjbGfO"
      },
      "source": [
        "# **Predicting Telco Customer Churn**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4XKg0PoDbGfP"
      },
      "source": [
        "Customer churn is a major problem and one of the most important concerns for large companies. Due to the direct effect on the revenues of the companies, especially in the telecom field, companies are seeking to develop means to predict potential customer to churn. Therefore, finding factors that increase customer churn is important to take necessary actions to reduce this churn.\n",
        "\n",
        "The main contribution of our work is to develop a churn prediction model which assists telecom operators to predict customers who are most likely subject to churn. The model developed in this work uses machine learning techniques on big data platform and builds a new way of features’ engineering and selection.\n",
        "\n",
        "Here we model the classification model from telco customer churn data. This data is consist of customer profile, customer subscription history, and their churn information. We will predict customer behavior to retain customers. You can analyze all relevant customer data and develop focused customer retention programs\n",
        "\n",
        "Each row represents a customer, each column contains customer’s attributes described below:\n",
        "1.   customerID : Customer ID\n",
        "2.   gender : Whether the customer is a male or a female\n",
        "3.   SeniorCitizen : Whether the customer is a senior citizen or not (1, 0)\n",
        "4.   Partner : Whether the customer has a partner or not (Yes, No)\n",
        "5.   Dependents : Whether the customer has dependents or not (Yes, No)\n",
        "6.   tenure : Number of months the customer has stayed with the company\n",
        "7.   PhoneService : Whether the customer has a phone service or not (Yes, No)\n",
        "8.   MultipleLines : Whether the customer has multiple lines or not (Yes, No, No phone service)\n",
        "9.   InternetService : Customer’s internet service provider (DSL, Fiber optic, No)\n",
        "10.   OnlineSecurity: Whether the customer has online security or not (Yes, No, No internet service)\n",
        "11.   OnlineBackup: Whether the customer has online backup or not (Yes, No, No internet service)\n",
        "12.   DeviceProtection: Whether the customer has device protection or not (Yes, No, No internet service)\n",
        "13.   TechSupport : Whether the customer has tech support or not (Yes, No, No internet service)\n",
        "14.   StreamingTV : Whether the customer has streaming TV or not (Yes, No, No internet service)\n",
        "15.   StreamingMovies : Whether the customer has streaming movies or not (Yes, No, No internet service)\n",
        "16.   Contract : The contract term of the customer (Month-to-month, One year, Two year)\n",
        "17.   PaperlessBilling : Whether the customer has paperless billing or not (Yes, No)\n",
        "18.   PaymentMethod : The customer’s payment method (Electronic check, Mailed check, Bank transfer (automatic), Credit card (automatic))\n",
        "19.   MonthlyCharges : The amount charged to the customer monthly\n",
        "20.   TotalCharges : The total amount charged to the customer\n",
        "21.   Churn Whether: the customer churned or not (Yes or No)\n",
        "\n",
        "Source: https://www.kaggle.com/blastchar/telco-customer-churn, https://journalofbigdata.springeropen.com/articles/10.1186/s40537-019-0191-6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inkLmZehq2VZ",
        "colab_type": "text"
      },
      "source": [
        "We use classification model to predict telco customer churn. Classification is the problem of identifying to which of a set of categories (sub-populations) a new observation belongs, on the basis of a training set of data containing observations (or instances) whose category membership is known."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KeByjWp4qywm"
      },
      "source": [
        "#### **Install and Import Libraries**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3hwJFIE7qywp"
      },
      "source": [
        "Before we begin to implement our classifier, we need to import some libraries to use them later. Here are the libraries we need to import."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9bER75oSqywp"
      },
      "source": [
        "***Install Library***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "stMgJKVpqywq",
        "colab": {}
      },
      "source": [
        "# Install Category Encoders\n",
        "! pip install category_encoders"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3PFlT-leqywu"
      },
      "source": [
        "***Import Libraries***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_ZFThsEhqywu",
        "colab": {}
      },
      "source": [
        "# Import Library for Data Manipulation\n",
        "import pandas as pd\n",
        "import category_encoders as ce\n",
        "\n",
        "# Import Library for Machine Learning\n",
        "import sklearn.metrics as metrics\n",
        "\n",
        "# Import Library for Visualization\n",
        "import matplotlib. pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GXXB8uj5bGfg"
      },
      "source": [
        "#### **Import Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Uh4l008bbGfj"
      },
      "source": [
        "Import our customer churn dataset into this notebook using Pandas library. Then, we discover the dataset information and statistics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Hg7C9XIlbGfk"
      },
      "source": [
        "***Customer Churn Data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NN1KD5tibGfl",
        "colab": {}
      },
      "source": [
        "# Import Dataset\n",
        "df_churn = pd.read_csv('https://raw.githubusercontent.com/machine-learning-ss/dataset/master/telco_customer_churn_dataset.csv', sep =',')\n",
        "df_churn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "URHzuyU9bGft",
        "colab": {}
      },
      "source": [
        "# Prints the Dataset Information\n",
        "df_churn.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EseXYuLybGfz",
        "colab": {}
      },
      "source": [
        "# Prints Descriptive Statistics\n",
        "df_churn.describe().transpose()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wbVrAzSLbGf6"
      },
      "source": [
        "#### **Explore the Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7CS86vdTbGf6"
      },
      "source": [
        "We need to visualize the data before implement our classifier. Data visualization is the act of taking information (data) and placing it into a visual context, such as a map or graph. Data visualizations make big and small data easier for the human brain to understand, and visualization also makes it easier to detect patterns, trends, and outliers in groups of data. Here we use Seaborn library."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9cPTbzZ2bGgA"
      },
      "source": [
        "***Visualize Correlation between Features***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iCC5gAsFbGgB",
        "colab": {}
      },
      "source": [
        "# Draw Correlation Map\n",
        "sns.clustermap(df_churn.corr(), center=0, cmap='vlag', linewidths=.75)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rkd0i6ymbGgF"
      },
      "source": [
        "#### **Preprocess the Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oY4QxU4DbGgG"
      },
      "source": [
        "We should transforms raw data into an understandable format. Raw data cannot be sent through a model because would cause certain errors. That is why we need to preprocess data before sending through a model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iS4AMjD0dyM_",
        "colab_type": "text"
      },
      "source": [
        "***Handling Missing Values***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYnemplIdvt2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check for Missing Values\n",
        "df_churn.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArSqZpVJd1E9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Search for Median Value\n",
        "median = df_churn['TotalCharges'].median()\n",
        "\n",
        "# Use Median to Replace Missing Values\n",
        "df_churn['TotalCharges'].fillna(median, inplace=True)\n",
        "\n",
        "# Check for Missing Values\n",
        "df_churn.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "id9i_45ubGgH"
      },
      "source": [
        "***Encode Categorical Data***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TpqmJ1iTbGgI"
      },
      "source": [
        "Data encoding purposed to transform a categorical data into binary numeric format. Here we use OneHotencoder module from sklearn to encode our categorical data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9yxXgjDd759",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Module\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Encoder\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "\n",
        "# Encode Categorical Data\n",
        "df_churn2 = pd.DataFrame(encoder.fit_transform(df_churn[['gender', 'InternetService', 'Contract', 'PaymentMethod']]))\n",
        "df_churn2.columns = encoder.get_feature_names(['gender', 'InternetService', 'Contract', 'PaymentMethod'])\n",
        "\n",
        "# Replace Categotical Data with Encoded Data\n",
        "df_churn_encoded = df_churn.drop(['gender', 'InternetService', 'Contract', 'PaymentMethod'] ,axis=1, inplace=True)\n",
        "df_churn_encoded = pd.concat([df_churn, df_churn2], axis=1)\n",
        "\n",
        "# Show Encoded Dataframe\n",
        "df_churn_encoded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VkaYQkKcbGgT"
      },
      "source": [
        "***Select Feature and Target***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2_zPIutrbGgU"
      },
      "source": [
        "Features are individual independent variables that act as the input in your system while target is whatever the output of the input variables. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KE9FII45bGgV",
        "colab": {}
      },
      "source": [
        "# Select Features\n",
        "feature = df_churn_encoded.drop(['customerID', 'Churn'], axis=1)\n",
        "feature"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qSDuoNTDbGga",
        "colab": {}
      },
      "source": [
        "# Select Target\n",
        "target = df_churn_encoded['Churn']\n",
        "target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gUW9C1qwbGgh"
      },
      "source": [
        "***Set Training and Testing Data***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xHxO6g4ObGgi"
      },
      "source": [
        "The next step is to split our data into tran and test sets. For this purpose, we use the scikit-learn's train_test_split function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hX8pjQ0jbGgj",
        "colab": {}
      },
      "source": [
        "# Import Module\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "\n",
        "# Set Training and Testing Data (70:30)\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "X_train, X_test, y_train, y_test = train_test_split(feature , target, shuffle = True, test_size=0.3, random_state=1)\n",
        "\n",
        "# Show the Training and Testing Data\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "icdHeeJXbGgo"
      },
      "source": [
        "#### **Modeling**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rS4PjuGzbGgp"
      },
      "source": [
        "##### **Decision Tree Classifier**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BBHAFKz6bGgp"
      },
      "source": [
        "Decision tree learning is one of the predictive modelling approaches used in statistics, data mining and machine learning. It uses a decision tree (as a predictive model) to go from observations about an item (represented in the branches) to conclusions about the item's target value (represented in the leaves)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aNJ6zGoebGgq"
      },
      "source": [
        "***Build Model***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NRHc96-GbGgr",
        "colab": {}
      },
      "source": [
        "# Import library\n",
        "from sklearn import tree\n",
        "\n",
        "# Modeling Decision Tree\n",
        "dtc= tree.DecisionTreeClassifier(min_impurity_decrease=0.01)\n",
        "dtc.fit(X_train, y_train)\n",
        "\n",
        "# Predict Test Data \n",
        "dtc_pred = dtc.predict(X_test)\n",
        "dtc_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mO-DUtS2bGgu",
        "colab": {}
      },
      "source": [
        "# Visualize Tree\n",
        "\n",
        "from sklearn.externals.six import StringIO  \n",
        "from IPython.display import Image  \n",
        "from sklearn.tree import export_graphviz\n",
        "import pydotplus\n",
        "\n",
        "feature_names = feature.columns[0:]\n",
        "\n",
        "dot_data = StringIO()\n",
        "export_graphviz(dtc, out_file=dot_data,  \n",
        "                filled=True, rounded=True,\n",
        "                special_characters=True,\n",
        "                class_names=['notchurn', 'churn'],\n",
        "                feature_names=feature_names)\n",
        "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
        "Image(graph.create_png())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "U2qlHNz4bGgy"
      },
      "source": [
        "***Model Evaluation***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ygPIsYQCbGgy",
        "colab": {}
      },
      "source": [
        "# Confsion Matrix\n",
        "cm_dtc = metrics.confusion_matrix(y_test, dtc_pred)\n",
        "cm_dtc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Iba5sqYWbGg3",
        "colab": {}
      },
      "source": [
        "# Accuracy, Precision, Recall\n",
        "acc_dtc = metrics.accuracy_score(y_test, dtc_pred)\n",
        "prec_dtc = metrics.precision_score(y_test, dtc_pred)\n",
        "rec_dtc = metrics.recall_score(y_test, dtc_pred)\n",
        "f1_dtc = metrics.f1_score(y_test, dtc_pred)\n",
        "kappa_dtc = metrics.cohen_kappa_score(y_test, dtc_pred)\n",
        "\n",
        "# Show Accuracy, Precision, Recall\n",
        "print('Accuracy:', acc_dtc)\n",
        "print('Precision:', prec_dtc)\n",
        "print('Recall:', rec_dtc)\n",
        "print('F1 Score:', f1_dtc)\n",
        "print('Cohens Kappa Score:', kappa_dtc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rEp-bxgTbGg8",
        "colab": {}
      },
      "source": [
        "# Import Visualization Package\n",
        "plt.rcParams['figure.figsize'] = (10, 10)\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "# Visualize ROC Curve\n",
        "dtc_prob = dtc.predict_proba(X_test)[::,1]\n",
        "fp_rate_dtc, tp_rate_dtc, _ = metrics.roc_curve(y_test,  dtc_prob)\n",
        "auc_dtc = metrics.roc_auc_score(y_test, dtc_prob)\n",
        "plt.plot(fp_rate_dtc, tp_rate_dtc, label='Decision Tree, auc='+str(auc_dtc))\n",
        "plt.xlabel('false positive rate') \n",
        "plt.ylabel('true positive rate')\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_7eSHeblbGhS"
      },
      "source": [
        "##### **Naive Bayes Classifier**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WVKiFfGnbGhT"
      },
      "source": [
        "Naïve Bayes classifiers are a family of simple \"probabilistic classifiers\" based on applying Bayes' theorem with strong (naïve) independence assumptions between the features. Naive Bayes is a simple technique for constructing classifiers: models that assign class labels to problem instances, represented as vectors of feature values, where the class labels are drawn from some finite set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hk2Ib82dbGhU"
      },
      "source": [
        "***Build Model***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "67QpBjEkbGhU",
        "colab": {}
      },
      "source": [
        "# Import Module\n",
        "from sklearn.naive_bayes import GaussianNB \n",
        "\n",
        "# Modeling Naive Bayes\n",
        "nb = GaussianNB()\n",
        "nb.fit(X_train, y_train)\n",
        "\n",
        "# Predict Test Data \n",
        "nb_pred = nb.predict(X_test)\n",
        "nb_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gOXC0fnobGhX"
      },
      "source": [
        "***Model Evaluation***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HwTr0qdnbGhY",
        "colab": {}
      },
      "source": [
        "# Confsion Matrix\n",
        "cm_nb = metrics.confusion_matrix(y_test, nb_pred)\n",
        "cm_nb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z3US8NjobGhb",
        "colab": {}
      },
      "source": [
        "# Accuracy, Precision, Recall\n",
        "acc_nb = metrics.accuracy_score(y_test, nb_pred)\n",
        "prec_nb = metrics.precision_score(y_test, nb_pred)\n",
        "rec_nb = metrics.recall_score(y_test, nb_pred)\n",
        "f1_nb = metrics.f1_score(y_test, nb_pred)\n",
        "kappa_nb = metrics.cohen_kappa_score(y_test, nb_pred)\n",
        "\n",
        "# Show Accuracy, Precision, Recall\n",
        "print('Accuracy:', acc_nb)\n",
        "print('Precision:', prec_nb)\n",
        "print('Recall:', rec_nb)\n",
        "print('F1 Score:', f1_nb)\n",
        "print('Cohens Kappa Score:', kappa_nb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_6-ZUJ7EbGhe",
        "colab": {}
      },
      "source": [
        "# Import Visualization Package\n",
        "plt.rcParams['figure.figsize'] = (10, 10)\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "# Visualize ROC Curve\n",
        "nb_prob = nb.predict_proba(X_test)[::,1]\n",
        "fp_rate_nb, tp_rate_nb, _ = metrics.roc_curve(y_test,  nb_prob)\n",
        "auc_nb = metrics.roc_auc_score(y_test, nb_prob)\n",
        "plt.plot(fp_rate_nb, tp_rate_nb, label='Naive Bayes, auc='+str(auc_nb))\n",
        "plt.xlabel('false positive rate') \n",
        "plt.ylabel('true positive rate')\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "g1lNfLFBbGhj"
      },
      "source": [
        "#### **Evaluating Models**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Brez-mpIbGhq"
      },
      "source": [
        "***Compare Model Performance***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gzzUSpf3bGhq",
        "colab": {}
      },
      "source": [
        "# Comparing Model Performance\n",
        "print('Decision Tree Accuracy =',acc_dtc)\n",
        "print('Decision Tree Precision =',prec_dtc)\n",
        "print('Decision Tree Recall =',rec_dtc)\n",
        "print('Decision Tree F1-Score =', f1_dtc)\n",
        "\n",
        "print('_______________________')\n",
        "\n",
        "print('Naive Bayes Accuracy =', acc_nb)\n",
        "print('Naive Bayes Precision =', prec_nb)\n",
        "print('Naive Bayes Recall =', rec_nb)\n",
        "print('Naive Bayes F1-Score =', f1_nb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "btf9CaWFbGht"
      },
      "source": [
        "***Compare ROC Curve***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rXuJJ77cbGht",
        "colab": {}
      },
      "source": [
        "# Comparing ROC Curve\n",
        "plt.plot(fp_rate_dtc,tp_rate_dtc,label='Decision Tree, auc='+str(auc_dtc))\n",
        "plt.plot(fp_rate_nb,tp_rate_nb,label='Naive Bayes, auc='+str(auc_nb))\n",
        "plt.title('ROC Curve')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6JyvIE7wqfBb"
      },
      "source": [
        "#### **Predict New Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AU5fFiTCqfBd"
      },
      "source": [
        "***Import New Data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8J1tKM7KqfBd",
        "colab": {}
      },
      "source": [
        "# Import New Dataset\n",
        "df_new_churn = pd.read_csv('https://raw.githubusercontent.com/machine-learning-ss/dataset/master/telco_customer_churn_new.csv', sep =',')\n",
        "df_new_churn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tFux4G-JqfBi"
      },
      "source": [
        "***Preprocess the New Data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VTta2kjxjOV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Module\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Encoder\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "\n",
        "# Encode Categorical Data\n",
        "df_new_churn2 = pd.DataFrame(encoder.fit_transform(df_new_churn[['gender', 'InternetService', 'Contract', 'PaymentMethod']]))\n",
        "df_new_churn2.columns = encoder.get_feature_names(['gender', 'InternetService', 'Contract', 'PaymentMethod'])\n",
        "\n",
        "# Concat the Encoded Data\n",
        "df_new_churn_encoded = df_new_churn.drop(['gender', 'InternetService', 'Contract', 'PaymentMethod'] ,axis=1, inplace=True)\n",
        "df_new_churn_encoded = pd.concat([df_new_churn, df_new_churn2], axis=1)\n",
        "\n",
        "# Show Encoded Dataframe\n",
        "df_new_churn_encoded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tGdN5T4yqfBm",
        "colab": {}
      },
      "source": [
        "# Select Features\n",
        "new_feature = df_new_churn_encoded.drop(['customerID'], axis=1)\n",
        "new_feature"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Wmt3-fv9qfBp"
      },
      "source": [
        "***Predict New Customer Data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QiMSWNkjqfBp",
        "colab": {}
      },
      "source": [
        "# Predict using Decision Tree Classifier\n",
        "dtc_prediction = pd.DataFrame(dtc.predict(new_feature), columns = ['dtc_prediction'])\n",
        "dtc_prediction.reset_index()\n",
        "dtc_prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XVDdIitKqfBv",
        "colab": {}
      },
      "source": [
        "# Predict using Naive Bayes Classifier\n",
        "nb_predicton = pd.DataFrame(nb.predict(new_feature), columns = ['nb_prediction'])\n",
        "nb_predicton.reset_index()\n",
        "nb_predicton"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MJ9JqFNNqfBx"
      },
      "source": [
        "***Show Prediction Comparation***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pFroQSmFqfBx",
        "colab": {}
      },
      "source": [
        "# Show Prediction Result\n",
        "churn_prediction = pd.concat([df_new_churn, dtc_prediction, nb_predicton], axis=1)\n",
        "churn_prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QmCnUQvfqfBz"
      },
      "source": [
        "***Save Prediction Result***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SoDOOOSXqfB0",
        "colab": {}
      },
      "source": [
        "# Save Prediction Result\n",
        "churn_prediction.to_csv('churn_prediction.csv', index=False)"
      ],
      "execution_count": 33,
      "outputs": []
    }
  ]
}